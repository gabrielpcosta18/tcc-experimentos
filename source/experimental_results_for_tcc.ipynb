{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Libraries\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from numpy import *\n",
    "\n",
    "#Nice graphing tools\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "import plotly\n",
    "import plotly.offline as py\n",
    "import plotly.tools as tls\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "\n",
    "import scipy.cluster.hierarchy as hac\n",
    "from scipy.cluster.hierarchy import cophenet, fcluster\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn import metrics\n",
    "\n",
    "PREPROCESSED_PATH = './../preprocessed/'\n",
    "IMAGES_PATH = './../images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading groupped data\n",
    "def read_groupped_data(filename):\n",
    "    timeSeries = pd.read_csv(filename,index_col=['Unnamed: 0'], parse_dates=['Unnamed: 0'])\n",
    "    timeSeries.rename(columns=lambda x: eval(x), inplace=True)\n",
    "    timeSeries.index = pd.to_datetime(timeSeries.index)\n",
    "    return timeSeries\n",
    "\n",
    "# Plot dendrogram\n",
    "def plot_dendrogram(Z, n_clusters):\n",
    "    plt.figure(figsize=(40, 16))\n",
    "    plt.title('Cluster Dendogram')\n",
    "    plt.xlabel('Timeseries')\n",
    "    plt.ylabel('Distance')\n",
    "    hac.dendrogram(\n",
    "        Z,\n",
    "        truncate_mode='lastp',\n",
    "        p=n_clusters,\n",
    "        show_leaf_counts=True,\n",
    "        show_contracted=True,\n",
    "        leaf_rotation=90.,  # rotates the x axis labels\n",
    "        leaf_font_size=8.,  # font size for the x axis labels\n",
    "    )\n",
    "    plt.show()\n",
    "    \n",
    "def plot_silhouette(timeSeries, silhouette_avg, n_clusters, cluster_labels, pic_name=None):\n",
    "    fig, ax1 = plt.subplots(1, 1)\n",
    "    fig.set_size_inches(18, 18)\n",
    "\n",
    "    ax1.set_xlim([-0.1, 1])\n",
    "\n",
    "    ax1.set_ylim([0, len(timeSeries) + (n_clusters + 3) * 10])\n",
    "    y_lower = 10\n",
    "    \n",
    "    sample_silhouette_values = metrics.silhouette_samples(timeSeries, cluster_labels)\n",
    "    silhouette_values = []\n",
    "    \n",
    "    for i in range(0, cluster_labels.max() + 1):\n",
    "        # Aggregate the silhouette scores for samples belonging to\n",
    "        # cluster i, and sort them\n",
    "        ith_cluster_silhouette_values = \\\n",
    "            sample_silhouette_values[cluster_labels == i]\n",
    "        \n",
    "        if ith_cluster_silhouette_values.shape[0] > 0:\n",
    "            ith_cluster_silhouette_values.sort()\n",
    "            silhouette_values.append(ith_cluster_silhouette_values)\n",
    "\n",
    "            size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "            y_upper = y_lower + size_cluster_i\n",
    "\n",
    "            color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "            ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                              0, ith_cluster_silhouette_values,\n",
    "                              facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "            # Label the silhouette plots with their cluster numbers at the middle\n",
    "            ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "            # Compute the new y_lower for next plot\n",
    "            y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "        else:\n",
    "            silhouette_values.append(pd.Series([]))\n",
    "\n",
    "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # The vertical line for average silhouette score of all the values\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax1.set_xticks([-1.0, -0.9,  -0.8, -0.7, -0.6, -0.5, -0.4, -0.3, -0.2, -0.1, 0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.8, 1])\n",
    "\n",
    "    # 2nd Plot showing the actual clusters formed\n",
    "    colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n",
    "    if pic_name:\n",
    "        fig.savefig(IMAGES_PATH + pic_name + '.png')\n",
    "    plt.suptitle((\"Silhouette analysis for Time Series Clustering on sample data \"\n",
    "                  \"with n_clusters = %d\" % n_clusters),\n",
    "                 fontsize=14, fontweight='bold')\n",
    "    return pd.Series(silhouette_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading time series data\n",
    "timeSeries = read_groupped_data(PREPROCESSED_PATH + 'timeseries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing time series without data\n",
    "timeSeries = timeSeries.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization between 0-1\n",
    "normalization = MinMaxScaler()\n",
    "\n",
    "# Z-score normalization\n",
    "standardization = StandardScaler()\n",
    "\n",
    "# Normalizing time series\n",
    "timeSeriesNormalized = pd.DataFrame(normalization.fit_transform(timeSeries), index=timeSeries.index, columns=timeSeries.columns)\n",
    "timeSeriesStandardized = pd.DataFrame(standardization.fit_transform(timeSeries), index=timeSeries.index, columns=timeSeries.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_normalized = timeSeriesNormalized.T\n",
    "X_standardized = timeSeriesStandardized.T\n",
    "\n",
    "# Applying ward method for clustering\n",
    "Z_normalized = hac.linkage(X_normalized, method='ward')\n",
    "Z_standardized = hac.linkage(X_standardized, method='ward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SILHOUETTE_AVG = True\n",
    "        \n",
    "if TEST_SILHOUETTE_AVG:\n",
    "    normalized_avg = pd.DataFrame(columns=['n_clusters', 'avg'])\n",
    "    standardized_avg = pd.DataFrame(columns=['n_clusters', 'avg'])\n",
    "    for i in range(3, 200):\n",
    "        cluster_labels = fcluster(Z_normalized, i, criterion=\"maxclust\")\n",
    "        avg = metrics.silhouette_score(X_normalized, cluster_labels, metric='euclidean')\n",
    "        normalized_avg = normalized_avg.append([[i, avg]])\n",
    "        \n",
    "        cluster_labels = fcluster(Z_standardized, i, criterion=\"maxclust\")\n",
    "        avg = metrics.silhouette_score(X_standardized, cluster_labels, metric='euclidean')\n",
    "        standardized_avg = standardized_avg.append([[i, avg]])\n",
    "    \n",
    "    normalized_avg.plot()\n",
    "    standardized_avg.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
