{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Libraries\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from numpy import *\n",
    "\n",
    "#Nice graphing tools\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "import plotly\n",
    "import plotly.offline as py\n",
    "import plotly.tools as tls\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from itertools import product\n",
    "import knntsp\n",
    "import warnings\n",
    "import importlib\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pickle\n",
    "\n",
    "NUM_CORES = 4\n",
    "PREPROCESSED_PATH = './../preprocessed/'\n",
    "RESULTS_PATH = './../results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading groupped data\n",
    "def read_groupped_data(filename):\n",
    "    timeSeries = pd.read_csv(filename,index_col=['Unnamed: 0'], parse_dates=['Unnamed: 0'])\n",
    "    timeSeries.rename(columns=lambda x: eval(x), inplace=True)\n",
    "    timeSeries.index = pd.to_datetime(timeSeries.index)\n",
    "    return timeSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CORES = 4\n",
    "RANDOM_STATE = 1\n",
    "TRAIN_SIZE = 0.86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading time series data\n",
    "timeSeries = read_groupped_data(PREPROCESSED_PATH + 'timeseries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing time series without data\n",
    "timeSeries = timeSeries.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels = pd.read_csv(PREPROCESSED_PATH + 'normalization_based_cluster_labels.csv', header=-1, index_col=[0])\n",
    "cluster_labels.columns = ['label']\n",
    "cluster_labels.head()\n",
    "\n",
    "simple_w_k = pd.read_csv(PREPROCESSED_PATH + 'simple_knntsp_w_k.csv')\n",
    "cluster_w_k = pd.read_csv(PREPROCESSED_PATH + 'cluster_knntsp_w_k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(knntsp)\n",
    "\n",
    "results_cluster_knn_real = []\n",
    "results_cluster_knn_predicted = []\n",
    "\n",
    "results_simple_knn_real = []\n",
    "results_simple_knn_predicted = []\n",
    "\n",
    "to_run_cluster_real = []\n",
    "to_run_cluster_predicted = []\n",
    "\n",
    "to_run_simple_real = []\n",
    "to_run_simple_predicted = []\n",
    "\n",
    "X = timeSeries.copy()\n",
    "_cluster_labels = cluster_labels.copy()\n",
    "\n",
    "for column in X.columns:\n",
    "    label = cluster_labels.iloc[X.T.index.get_loc(column)][0]\n",
    "    \n",
    "    w_k = simple_w_k\n",
    "    clust_w_k = cluster_w_k[cluster_w_k.cluster_label==label]\n",
    "    if len(clust_w_k) == 0:\n",
    "        clust_w_k = simple_w_k\n",
    "    \n",
    "    to_run_cluster_real.append([X, column, _cluster_labels, int(clust_w_k.iloc[0]['w']), int(clust_w_k.iloc[0]['k']), TRAIN_SIZE, True])\n",
    "    to_run_cluster_predicted.append([X, column, _cluster_labels, int(clust_w_k.iloc[0]['w']), int(clust_w_k.iloc[0]['k']), TRAIN_SIZE, False])\n",
    "    \n",
    "    to_run_simple_predicted.append([X, column, int(simple_w_k['w'][0]), int(simple_w_k['k'][0]), TRAIN_SIZE, False, label, False])\n",
    "    to_run_simple_real.append([X, column, int(simple_w_k['w'][0]), int(simple_w_k['k'][0]), TRAIN_SIZE, False, label, True])\n",
    "\n",
    "with Pool(NUM_CORES) as pool:\n",
    "    results_cluster_knn_real = pool.starmap(knntsp.predict_with_cluster_knn, to_run_cluster_real)\n",
    "    results_simple_knn_real = pool.starmap(knntsp.predict_with_knn, to_run_simple_real)\n",
    "    results_cluster_knn_predicted = pool.starmap(knntsp.predict_with_cluster_knn, to_run_cluster_predicted)\n",
    "    results_simple_knn_predicted = pool.starmap(knntsp.predict_with_knn, to_run_simple_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PICKLE_RESULTS = False\n",
    "\n",
    "if SAVE_PICKLE_RESULTS:\n",
    "    output = open(RESULTS_PATH + 'results_cluster_knn_real.pk', 'wb')\n",
    "    pickle.dump(results_cluster_knn_real, output)\n",
    "    output.close()\n",
    "    \n",
    "    output = open(RESULTS_PATH + 'results_simple_knn_real.pk', 'wb')\n",
    "    pickle.dump(results_simple_knn_real, output)\n",
    "    output.close()\n",
    "    \n",
    "    output = open(RESULTS_PATH + 'results_cluster_knn_predicted.pk', 'wb')\n",
    "    pickle.dump(results_cluster_knn_predicted, output)\n",
    "    output.close()\n",
    "    \n",
    "    output = open(RESULTS_PATH + 'results_simple_knn_predicted.pk', 'wb')\n",
    "    pickle.dump(results_simple_knn_predicted, output)\n",
    "    output.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
